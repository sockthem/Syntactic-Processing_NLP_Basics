{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXsu8MxUVAKT"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kXr4Cxh2VAKZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Eq-7JCT6VAKa"
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItxQ587VVAKb"
   },
   "source": [
    "### Read reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q1pr6bbsVAKb"
   },
   "outputs": [],
   "source": [
    "con=open(r\"C:\\Users\\Ranajoy Bhattacharya\\Downloads\\Syntactic-Processing-master\\Syntactic-Processing-NLP\\POS Tagging Case Study\\Dataset\\Samsung.txt\",'r', encoding=\"utf-8\")\n",
    "samsung_reviews=con.read()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f4GyRJMEVAKb",
    "outputId": "29fcc27e-8558-4e67-bec3-b677797f4601"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46355"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samsung_reviews.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU4ZvurwVAKc"
   },
   "source": [
    "### Dataset is a text file where each review is in a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bPT-wYC2VAKd",
    "outputId": "93ff4281-69f0-4cfc-b686-a64e9cf439ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\",\n",
       " 'nice phone, nice up grade from my pantach revue. Very clean set up and easy set up. never had an android phone but they are fantastic to say the least. perfect size for surfing and social media. great phone samsung',\n",
       " 'Very pleased',\n",
       " 'It works good but it goes slow sometimes but its a very good phone I love it']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsung_reviews.split(\"\\n\")[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUi5gE7WVAKd"
   },
   "source": [
    "### Will our hypothesis hold on real world data? `Product features---POS_NOUN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yUx96iRtVAKg"
   },
   "outputs": [],
   "source": [
    "review1=samsung_reviews.split(\"\\n\")[0]\n",
    "review1=nlp(review1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKt6ZNPnVAKg"
   },
   "source": [
    "### Lets do nlp parse on part of one review in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gOCZxFp_VAKh",
    "outputId": "1465e5eb-d533-42dc-e890-c76dfa65d589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --- I --- PRON\n",
      "feel --- feel --- VERB\n",
      "so --- so --- ADV\n",
      "LUCKY --- lucky --- ADJ\n",
      "to --- to --- PART\n",
      "have --- have --- AUX\n",
      "found --- find --- VERB\n",
      "this --- this --- DET\n",
      "used --- use --- VERB\n",
      "( --- ( --- PUNCT\n"
     ]
    }
   ],
   "source": [
    "for tok in review1[0:10]:\n",
    "    print(tok.text,\"---\",tok.lemma_,\"---\",tok.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOBlgcu0VAKh"
   },
   "source": [
    "#### Real world data is usually messy, observe the words `found` and `used`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yB1t1bPTVAKh"
   },
   "outputs": [],
   "source": [
    "pos = []\n",
    "lemma = []\n",
    "text = []\n",
    "for tok in review1:\n",
    "    pos.append(tok.pos_)\n",
    "    lemma.append(tok.lemma_)\n",
    "    text.append(tok.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G3LDkWepVAKi",
    "outputId": "0e2c0671-4157-4ae6-a397-08ef8ad1dfdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel</td>\n",
       "      <td>feel</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so</td>\n",
       "      <td>so</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LUCKY</td>\n",
       "      <td>lucky</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma   pos\n",
       "0      I      I  PRON\n",
       "1   feel   feel  VERB\n",
       "2     so     so   ADV\n",
       "3  LUCKY  lucky   ADJ\n",
       "4     to     to  PART"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_table = pd.DataFrame({'text':text,'lemma':lemma,'pos':pos})\n",
    "nlp_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FEXKFzlPVAKi",
    "outputId": "15fa5020-0bcb-4ba1-8d31-938fc204de91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phone      3\n",
       "one        2\n",
       "honesty    1\n",
       "year       1\n",
       "upgrade    1\n",
       "line       1\n",
       "seller     1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get most frequent lemma forms of nouns\n",
    "nlp_table[nlp_table['pos']=='NOUN']['lemma'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-uR8q-LVAKi"
   },
   "source": [
    "#### It seems possible that if we extract all the nouns from the reviews and look at the top 5 most frequent lemmatised noun forms, we will be able to identify `What people are talking about?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOvqBuwgVAKj"
   },
   "source": [
    "### Lets repeat this experiment on a larger set of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RsDUv3X1VAKj"
   },
   "outputs": [],
   "source": [
    "nouns = []\n",
    "for review in samsung_reviews.split(\"\\n\")[0:100]:\n",
    "    doc = nlp(review)\n",
    "    for tok in doc:\n",
    "        if tok.pos_==\"NOUN\":\n",
    "            nouns.append(tok.lemma_.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrVi3UPTVAKj"
   },
   "source": [
    "### Lets add some way of keeping track of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zNhp_45EVAKj",
    "outputId": "bf7700fd-7e6c-46a2-f8ad-e6282812b14c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:12<00:00, 77.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "phone      1208\n",
       "battery      92\n",
       "time         90\n",
       "price        87\n",
       "screen       86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "nouns = []\n",
    "for review in tqdm(samsung_reviews.split(\"\\n\")[0:1000]):\n",
    "    doc = nlp(review)\n",
    "    for tok in doc:\n",
    "        if tok.pos_==\"NOUN\":\n",
    "            nouns.append(tok.lemma_.lower())\n",
    "pd.Series(nouns).value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jai2hnfoVAKk",
    "outputId": "4d74cbee-10fe-444d-9c8d-f3a1a7f4ff2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46355"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samsung_reviews.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94gZ5gxLVAKk"
   },
   "source": [
    "### Did you notice anything? What do you think will be the time taken to process all the reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op_ftvWyVAKk",
    "outputId": "3b9fbbd0-87f3-432b-df9d-0579267a250f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(46355//1000)*17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDMknUOXVAKl",
    "outputId": "fe2f2b6f-65d5-45e0-f58e-5cc9408ab0e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "782//60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PsJmzrtVAKl"
   },
   "source": [
    "## Summary\n",
    "- POS tag based rule seems to be working well\n",
    "- We need to figure out a way to reduce the time taken to process reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf7AFwbiVAKl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "POS2.ipynb.txt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
